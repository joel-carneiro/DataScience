{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06ee2eec-bfa4-4274-9edc-e8b401f67c13",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Tratando token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46f0f719-aabb-4dc2-a627-e2f308c551e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/artigos.txt', 'r') as f:\n",
    "    article = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4815a4d9-448b-4a9d-823e-1d177734c044",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/joel/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e8747e5-2389-48ef-ac6a-454084d9b808",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = nltk.tokenize.word_tokenize(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5ea66ed-853c-4cee-a2ac-f59fa6e91a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_words(token):\n",
    "    return [word for word in token if word.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c02cedb-438f-4c70-b71b-5961f320adae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_words(words):\n",
    "    return [word.lower() for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7add9a65-a6da-493a-96ff-15f41be8187d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(words):\n",
    "    return set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d3ccef4-36de-44d5-afee-fed36bc2dde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def treat_token(token):\n",
    "    token = separate_words(token)\n",
    "    token = normalize_words(token)\n",
    "    token = remove_duplicates(token)\n",
    "    \n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e21099d-9e7d-4604-990e-a2aa6a623934",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = treat_token(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd9154c-2056-4ef1-bb76-8a90c181dc31",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Criando o corretor ortográfico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1fa74ab-c334-4fdb-a593-045001041ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_letter(word):\n",
    "    letters = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'\n",
    "    tests = []\n",
    "    \n",
    "    for i in range(len(word)):\n",
    "        for letter in letters:\n",
    "            tests.append(word[:i] + letter + word[i:])\n",
    "\n",
    "    return tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fc715b6-b0c7-4372-a7ba-cc83c905e468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_letter(word):\n",
    "    \n",
    "    tests = []\n",
    "    \n",
    "    for i in range(1, len(word) + 1, 1):\n",
    "        left = word[:i - 1]\n",
    "        right = word[i:]\n",
    "        tests.append(left + right)\n",
    "\n",
    "    return tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be821aba-6d53-496c-82d3-4672a5c3b017",
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_letters(word):\n",
    "    \n",
    "    tests = []\n",
    "    letters = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'\n",
    "    for letter in letters:\n",
    "        for i in range(1, len(word) + 1, 1):\n",
    "            left = word[:i - 1]\n",
    "            right = word[i:]\n",
    "            tests.append(left + letter + right)\n",
    "\n",
    "    return tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f5767b6-a3f2-4502-9992-5086aa877729",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_words(word):\n",
    "    generated_words = []\n",
    "    generated_words.extend(add_letter(word))\n",
    "    generated_words.extend(remove_letter(word))\n",
    "    generated_words.extend(swap_letters(word))\n",
    "    \n",
    "    return generated_words\n",
    "\n",
    "def turbocharged_generator(generated_words):\n",
    "    new_words = []\n",
    "    \n",
    "    for word in generated_words:\n",
    "        new_words += generate_words(word)\n",
    "    \n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77fcd403-730d-45c6-9c28-d49f7546b64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_words = len(words)\n",
    "frequency = nltk.FreqDist(words)\n",
    "\n",
    "def calculate_probability(word):\n",
    "    return frequency[word] / total_words\n",
    "\n",
    "vocabulary = set(words)\n",
    "\n",
    "def spell_checker(word):\n",
    "    generated_words = generate_words(word)\n",
    "    correct_word = max(generated_words, key = calculate_probability)\n",
    "    \n",
    "    return correct_word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ead5316-a6bd-46c1-a272-5d444bf7af98",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Avaliando corretor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40a32301-4b16-4c6d-93b9-518340486af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxa de acerto: 63.44% de 186 palavras\n"
     ]
    }
   ],
   "source": [
    "def evaluate_spell_checker():\n",
    "    f = open('data/palavras.txt', 'r')\n",
    "    test_list = []\n",
    "    list_result = []\n",
    "    \n",
    "    for test in f:\n",
    "        correct, false = test.split()\n",
    "        test_list.append((correct, false))\n",
    "    f.close()\n",
    "    \n",
    "    for test in test_list:\n",
    "        result = test[0] == spell_checker(test[1])\n",
    "        list_result.append(result)\n",
    "        \n",
    "    evaluate = list_result.count(True) / len(list_result)\n",
    "    \n",
    "    print(f\"Taxa de acerto: {(evaluate * 100):.2f}% de {len(test_list)} palavras\")\n",
    "    \n",
    "evaluate_spell_checker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713d3ab2-c32b-4281-8949-6f0b608f43fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
